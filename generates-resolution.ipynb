{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10690189,"sourceType":"datasetVersion","datasetId":6623669},{"sourceId":10690225,"sourceType":"datasetVersion","datasetId":6623695}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Define file paths\ninput_file = \"/kaggle/input/loki-dataset/switch\"  # Change to actual file path if needed\noutput_csv = \"network_logs.csv\"\nfiltered_csv = \"critical_networks.csv\"\n\n# Define column names\ncolumns = [\"Timestamp\", \"Log_Level\", \"IP_Address\", \"Message\"]\n\n# Read the log file and convert it to CSV\ndf = pd.read_csv(input_file, sep=\"\\t\", names=columns, header=None, encoding=\"utf-8\", on_bad_lines=\"skip\")\ndf.to_csv(output_csv, index=False)\n\n# Define criteria for filtering critical networks\ncritical_keywords = [\"Error\", \"Critical\", \"Failure\", \"Down\", \"Denied\", \"Timeout\"]\ncritical_networks = df[df[\"Log_Level\"].str.contains(\"|\".join(critical_keywords), case=False, na=False)]\n\n# Save critical network logs\ncritical_networks.to_csv(filtered_csv, index=False)\n\nprint(f\"Converted log file saved as: {output_csv}\")\nprint(f\"Filtered critical network logs saved as: {filtered_csv}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:18:22.213045Z","iopub.execute_input":"2025-02-08T04:18:22.213328Z","iopub.status.idle":"2025-02-08T04:18:24.028670Z","shell.execute_reply.started":"2025-02-08T04:18:22.213298Z","shell.execute_reply":"2025-02-08T04:18:24.027605Z"}},"outputs":[{"name":"stdout","text":"Converted log file saved as: network_logs.csv\nFiltered critical network logs saved as: critical_networks.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# Define file paths\ninput_file = \"/kaggle/input/loki-dataset/switch\"  # Change to actual file path if needed\noutput_csv = \"network_logs.csv\"\nfiltered_critical_csv = \"critical_networks.csv\"\nfiltered_fault_csv = \"fault_networks.csv\"\n\n# Define column names\ncolumns = [\"Timestamp\", \"Log_Level\", \"IP_Address\", \"Message\"]\n\n# Read the log file and convert it to CSV\ndf = pd.read_csv(input_file, sep=\"\\t\", names=columns, header=None, encoding=\"utf-8\", on_bad_lines=\"skip\")\ndf.to_csv(output_csv, index=False)\n\n# Define criteria for filtering critical networks\ncritical_keywords = [\"Error\", \"Critical\", \"Failure\", \"Down\", \"Denied\", \"Timeout\"]\nfault_keywords = [\"Fault\", \"Disconnected\", \"Overload\", \"Unreachable\", \"Dropped\"]\n\ncritical_networks = df[df[\"Log_Level\"].str.contains(\"|\".join(critical_keywords), case=False, na=False)]\nfault_networks = df[df[\"Log_Level\"].str.contains(\"|\".join(fault_keywords), case=False, na=False)]\n\n# Save filtered logs\ncritical_networks.to_csv(filtered_critical_csv, index=False)\nfault_networks.to_csv(filtered_fault_csv, index=False)\n\nprint(f\"Converted log file saved as: {output_csv}\")\nprint(f\"Filtered critical network logs saved as: {filtered_critical_csv}\")\nprint(f\"Filtered fault-based network logs saved as: {filtered_fault_csv}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T19:34:13.936810Z","iopub.execute_input":"2025-02-07T19:34:13.937166Z","iopub.status.idle":"2025-02-07T19:34:14.890483Z","shell.execute_reply.started":"2025-02-07T19:34:13.937135Z","shell.execute_reply":"2025-02-07T19:34:14.889770Z"}},"outputs":[{"name":"stdout","text":"Converted log file saved as: network_logs.csv\nFiltered critical network logs saved as: critical_networks.csv\nFiltered fault-based network logs saved as: fault_networks.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/input/csv-dataset/network_logs.csv\")\ndf1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:19:04.489601Z","iopub.execute_input":"2025-02-08T04:19:04.490012Z","iopub.status.idle":"2025-02-08T04:19:04.895325Z","shell.execute_reply.started":"2025-02-08T04:19:04.489975Z","shell.execute_reply":"2025-02-08T04:19:04.894483Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                  Timestamp    Log_Level    IP_Address  \\\n0       2025-01-17 17:45:00    Cron.Info  10.163.160.2   \n1       2025-01-17 17:45:00    Cron.Info  10.163.160.2   \n2       2025-01-17 17:45:01    Cron.Info  10.163.160.2   \n3       2025-01-17 17:48:59    User.Info  10.163.160.2   \n4       2025-01-17 17:48:59  Local4.Info  10.163.160.2   \n...                     ...          ...           ...   \n141480  2025-02-03 22:13:02  Local4.Info  10.163.160.2   \n141481  2025-02-03 22:13:31  Local4.Info  10.163.160.2   \n141482  2025-02-03 22:15:00    Cron.Info  10.163.160.2   \n141483  2025-02-03 22:15:00    Cron.Info  10.163.160.2   \n141484  2025-02-03 22:15:00    Cron.Info  10.163.160.2   \n\n                                                  Message  \n0        /usr/sbin/cron[32897]: (root) CMD (newsyslog -X)  \n1       /usr/sbin/cron[32898]: (root) CMD (   /usr/lib...  \n2       /usr/sbin/cron[32896]: (root) MAIL (mailed 39 ...  \n3       dc-pfe[17765]: tvp_drv_syspld_read: i2c access...  \n4       fpc1 tvp_drv_syspld_read: i2c access retry cou...  \n...                                                   ...  \n141480  fpc0 tvp_drv_syspld_read: i2c access retry cou...  \n141481  fpc4 tvp_drv_syspld_read: i2c access retry cou...  \n141482  /usr/sbin/cron[4759]: (root) CMD (   /usr/libe...  \n141483    /usr/sbin/cron[4758]: (root) CMD (newsyslog -X)  \n141484  /usr/sbin/cron[4757]: (root) MAIL (mailed 39 b...  \n\n[141485 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>Log_Level</th>\n      <th>IP_Address</th>\n      <th>Message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2025-01-17 17:45:00</td>\n      <td>Cron.Info</td>\n      <td>10.163.160.2</td>\n      <td>/usr/sbin/cron[32897]: (root) CMD (newsyslog -X)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2025-01-17 17:45:00</td>\n      <td>Cron.Info</td>\n      <td>10.163.160.2</td>\n      <td>/usr/sbin/cron[32898]: (root) CMD (   /usr/lib...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2025-01-17 17:45:01</td>\n      <td>Cron.Info</td>\n      <td>10.163.160.2</td>\n      <td>/usr/sbin/cron[32896]: (root) MAIL (mailed 39 ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2025-01-17 17:48:59</td>\n      <td>User.Info</td>\n      <td>10.163.160.2</td>\n      <td>dc-pfe[17765]: tvp_drv_syspld_read: i2c access...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2025-01-17 17:48:59</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc1 tvp_drv_syspld_read: i2c access retry cou...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>141480</th>\n      <td>2025-02-03 22:13:02</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc0 tvp_drv_syspld_read: i2c access retry cou...</td>\n    </tr>\n    <tr>\n      <th>141481</th>\n      <td>2025-02-03 22:13:31</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc4 tvp_drv_syspld_read: i2c access retry cou...</td>\n    </tr>\n    <tr>\n      <th>141482</th>\n      <td>2025-02-03 22:15:00</td>\n      <td>Cron.Info</td>\n      <td>10.163.160.2</td>\n      <td>/usr/sbin/cron[4759]: (root) CMD (   /usr/libe...</td>\n    </tr>\n    <tr>\n      <th>141483</th>\n      <td>2025-02-03 22:15:00</td>\n      <td>Cron.Info</td>\n      <td>10.163.160.2</td>\n      <td>/usr/sbin/cron[4758]: (root) CMD (newsyslog -X)</td>\n    </tr>\n    <tr>\n      <th>141484</th>\n      <td>2025-02-03 22:15:00</td>\n      <td>Cron.Info</td>\n      <td>10.163.160.2</td>\n      <td>/usr/sbin/cron[4757]: (root) MAIL (mailed 39 b...</td>\n    </tr>\n  </tbody>\n</table>\n<p>141485 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\ndef filter_critical_network_data(log_file, output_csv):\n    \"\"\"\n    Filters critical network data from a log file and saves it to a CSV file.\n\n    Args:\n        log_file (str): Path to the network log file (CSV).\n        output_csv (str): Path to save the filtered data (CSV).\n    \"\"\"\n\n    try:\n        # Read the CSV file into a Pandas DataFrame\n        df = pd.read_csv(\"/kaggle/input/csv-dataset/network_logs.csv\")\n\n        # Define keywords indicating critical network events\n        critical_keywords = [\n            \"DOWN\",\n            \"ERROR\",\n            \"FAILURE\",\n            \"CRITICAL\",\n            \"WARNING\",\n            \"REJECTED\",\n            \"Authentication failure\",\n            \"i2c access retry count\",\n            \"ifd_mdown\",  # Interface down\n            \"SNMP_TRAP_LINK_DOWN\"  # Link down trap\n        ]\n\n        # Create a boolean mask based on whether any of the keywords are present in the 'Message' column\n        mask = df['Message'].str.contains('|'.join(critical_keywords), case=False, na=False)\n\n        # Apply the mask to filter the DataFrame\n        critical_network_df = df[mask]\n\n        # Save the filtered DataFrame to a new CSV file\n        critical_network_df.to_csv(output_csv, index=False)\n\n        print(f\"Critical network data filtered and saved to {output_csv}\")\n\n    except FileNotFoundError:\n        print(f\"Error: The file {log_file} was not found.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\n# Define input and output file paths\nlog_file = \"network_logs.csv\"\noutput_csv = \"critical_network_data.csv\"\n\n# Run the function to filter and save the critical network data\nfilter_critical_network_data(log_file, output_csv)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:19:05.036856Z","iopub.execute_input":"2025-02-08T04:19:05.037142Z","iopub.status.idle":"2025-02-08T04:19:07.171568Z","shell.execute_reply.started":"2025-02-08T04:19:05.037120Z","shell.execute_reply":"2025-02-08T04:19:07.170841Z"}},"outputs":[{"name":"stdout","text":"Critical network data filtered and saved to critical_network_data.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"df2 = pd.read_csv(\"/kaggle/working/critical_network_data.csv\")\ndf2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:19:07.172455Z","iopub.execute_input":"2025-02-08T04:19:07.172661Z","iopub.status.idle":"2025-02-08T04:19:07.276336Z","shell.execute_reply.started":"2025-02-08T04:19:07.172643Z","shell.execute_reply":"2025-02-08T04:19:07.275508Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                 Timestamp    Log_Level    IP_Address  \\\n0      2025-01-17 17:48:59    User.Info  10.163.160.2   \n1      2025-01-17 17:48:59  Local4.Info  10.163.160.2   \n2      2025-01-17 18:06:47  Local4.Info  10.163.160.2   \n3      2025-01-17 18:13:59    User.Info  10.163.160.2   \n4      2025-01-17 18:13:59  Local4.Info  10.163.160.2   \n...                    ...          ...           ...   \n58444  2025-02-03 22:05:04  Local4.Info  10.163.160.2   \n58445  2025-02-03 22:07:32  Local4.Info  10.163.160.2   \n58446  2025-02-03 22:12:19  Local4.Info  10.163.160.2   \n58447  2025-02-03 22:13:02  Local4.Info  10.163.160.2   \n58448  2025-02-03 22:13:31  Local4.Info  10.163.160.2   \n\n                                                 Message  \n0      dc-pfe[17765]: tvp_drv_syspld_read: i2c access...  \n1      fpc1 tvp_drv_syspld_read: i2c access retry cou...  \n2      fpc4 tvp_drv_syspld_read: i2c access retry cou...  \n3      dc-pfe[17765]: tvp_drv_syspld_read: i2c access...  \n4      fpc1 tvp_drv_syspld_read: i2c access retry cou...  \n...                                                  ...  \n58444  fpc2 tvp_drv_syspld_read: i2c access retry cou...  \n58445  fpc0 tvp_drv_syspld_read: i2c access retry cou...  \n58446  fpc3 tvp_drv_syspld_read: i2c access retry cou...  \n58447  fpc0 tvp_drv_syspld_read: i2c access retry cou...  \n58448  fpc4 tvp_drv_syspld_read: i2c access retry cou...  \n\n[58449 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>Log_Level</th>\n      <th>IP_Address</th>\n      <th>Message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2025-01-17 17:48:59</td>\n      <td>User.Info</td>\n      <td>10.163.160.2</td>\n      <td>dc-pfe[17765]: tvp_drv_syspld_read: i2c access...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2025-01-17 17:48:59</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc1 tvp_drv_syspld_read: i2c access retry cou...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2025-01-17 18:06:47</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc4 tvp_drv_syspld_read: i2c access retry cou...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2025-01-17 18:13:59</td>\n      <td>User.Info</td>\n      <td>10.163.160.2</td>\n      <td>dc-pfe[17765]: tvp_drv_syspld_read: i2c access...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2025-01-17 18:13:59</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc1 tvp_drv_syspld_read: i2c access retry cou...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58444</th>\n      <td>2025-02-03 22:05:04</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc2 tvp_drv_syspld_read: i2c access retry cou...</td>\n    </tr>\n    <tr>\n      <th>58445</th>\n      <td>2025-02-03 22:07:32</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc0 tvp_drv_syspld_read: i2c access retry cou...</td>\n    </tr>\n    <tr>\n      <th>58446</th>\n      <td>2025-02-03 22:12:19</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc3 tvp_drv_syspld_read: i2c access retry cou...</td>\n    </tr>\n    <tr>\n      <th>58447</th>\n      <td>2025-02-03 22:13:02</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc0 tvp_drv_syspld_read: i2c access retry cou...</td>\n    </tr>\n    <tr>\n      <th>58448</th>\n      <td>2025-02-03 22:13:31</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc4 tvp_drv_syspld_read: i2c access retry cou...</td>\n    </tr>\n  </tbody>\n</table>\n<p>58449 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"!pip install langchain_community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:19:07.278007Z","iopub.execute_input":"2025-02-08T04:19:07.278296Z","iopub.status.idle":"2025-02-08T04:19:17.119585Z","shell.execute_reply.started":"2025-02-08T04:19:07.278273Z","shell.execute_reply":"2025-02-08T04:19:17.118651Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain_community\n  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\nCollecting langchain-core<1.0.0,>=0.3.34 (from langchain_community)\n  Downloading langchain_core-0.3.34-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain<1.0.0,>=0.3.18 (from langchain_community)\n  Downloading langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.11)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.3)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nCollecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain<1.0.0,>=0.3.18->langchain_community)\n  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<1.0.0,>=0.3.18->langchain_community) (2.11.0a1)\nCollecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_community) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain_community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain_community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain_community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain_community) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain_community) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.26.4->langchain_community) (2.4.1)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain_community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain_community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.28.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain_community) (2.28.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.26.4->langchain_community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.26.4->langchain_community) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.26.4->langchain_community) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.26.4->langchain_community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.26.4->langchain_community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.2.2)\nDownloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain-0.3.18-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.34-py3-none-any.whl (412 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.0/413.0 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\nDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\nDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nInstalling collected packages: python-dotenv, httpx-sse, async-timeout, pydantic-settings, langchain-core, langchain-text-splitters, langchain, langchain_community\n  Attempting uninstall: async-timeout\n    Found existing installation: async-timeout 5.0.1\n    Uninstalling async-timeout-5.0.1:\n      Successfully uninstalled async-timeout-5.0.1\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.25\n    Uninstalling langchain-core-0.3.25:\n      Successfully uninstalled langchain-core-0.3.25\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.3\n    Uninstalling langchain-text-splitters-0.3.3:\n      Successfully uninstalled langchain-text-splitters-0.3.3\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.12\n    Uninstalling langchain-0.3.12:\n      Successfully uninstalled langchain-0.3.12\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed async-timeout-4.0.3 httpx-sse-0.4.0 langchain-0.3.18 langchain-core-0.3.34 langchain-text-splitters-0.3.6 langchain_community-0.3.17 pydantic-settings-2.7.1 python-dotenv-1.0.1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"input_path = \"/kaggle/working/critical_network_data.csv\"\n\n# Read the CSV file\ndf = pd.read_csv(input_path)\n\n# Select first 100 rows\ndf_selected = df.head(100)\n\n# Optionally, save it to a new CSV file\nout_path = \"/kaggle/working/critical_network_data_selected.csv\"\ndf_selected.to_csv(out_path, index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:19:17.121050Z","iopub.execute_input":"2025-02-08T04:19:17.121400Z","iopub.status.idle":"2025-02-08T04:19:17.227115Z","shell.execute_reply.started":"2025-02-08T04:19:17.121346Z","shell.execute_reply":"2025-02-08T04:19:17.226312Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import openai\nimport pandas as pd\nfrom langchain.prompts.chat import ChatPromptTemplate\nfrom langchain.chat_models import AzureChatOpenAI\nfrom langchain.schema import SystemMessage, HumanMessage\nfrom tqdm import tqdm  # Import tqdm for progress tracking\n\nChat_Model = {\n    \"openai_api_type\": \"azure\",\n    \"deployment_name\": 'ic11-hack-43-gpt-4o-mini',\n    \"model_name\": \"gpt-4o-mini\",\n    \"openai_api_base\": \"https://hac-openai-instance-03.openai.azure.com/\",\n    \"openai_api_version\": \"2024-05-01-preview\",\n    \"openai_api_key\": \"8mKCtXvWx2EoLkrx0At91ZMLEWlLXlq9wxyQ33eeXFzXJ9VFxWmKJQQJ99BBACYeBjFXJ3w3AAABACOGrn5G\",\n    # \"temperature\": 0 # 0-1 as you increse it, creativity increses\n}\n\nchat_model = AzureChatOpenAI(openai_api_type=Chat_Model['openai_api_type'],\n                                        deployment_name=Chat_Model['deployment_name'],\n                                        model_name=Chat_Model['model_name'],\n                                        azure_endpoint=Chat_Model['openai_api_base'],\n                                        openai_api_version=Chat_Model['openai_api_version'],\n                                        openai_api_key=Chat_Model['openai_api_key'],\n                                        temperature=0)\n\ndef generate_resolution_with_llm(message):\n    \"\"\"\n    Generates a resolution for a given log message using a language model.\n\n    Args:\n        message (str): The log message.\n\n    Returns:\n        str: The generated resolution from the LLM.\n    \"\"\"\n\n    system_message = SystemMessage(\n        content=\"You are an expert network engineer providing resolutions for network log messages using maximum 200 words.\"\n    )\n    human_message = HumanMessage(\n        content=f\"Provide a detailed resolution for the following network log message: {message}\"\n    )\n\n    response = chat_model.invoke([system_message, human_message])\n    return response.content\n\ndef add_llm_resolution_to_csv(input_path, output_path):\n    \"\"\"\n    Adds a 'Resolution' column to a CSV file containing network log messages,\n    generating resolutions using a language model.\n\n    Args:\n        input_path (str): Path to the input CSV file.\n        output_path (str): Path to save the output CSV file with resolutions.\n    \"\"\"\n\n    try:\n        df = pd.read_csv(input_path)\n\n        # Initialize tqdm for progress tracking\n        tqdm.pandas(desc=\"Generating Resolutions\")\n\n        # Generate and add resolutions using the LLM with progress tracking\n        df['Resolution'] = df['Message'].progress_apply(generate_resolution_with_llm)\n\n        # Save the DataFrame with resolutions to a new CSV file\n        df.to_csv(output_path, index=False)\n\n        print(f\"Resolutions generated and saved to {output_path}\")\n\n    except FileNotFoundError:\n        print(f\"Error: The file {input_path} was not found.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\n# Define input and output file paths\ninput_path = \"/kaggle/working/critical_network_data_selected.csv\"\noutput_path = \"critical_network_data_with_resolution.csv\"\n\n# Run the function to add resolutions to the CSV file\nadd_llm_resolution_to_csv(input_path, output_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:20:33.331850Z","iopub.execute_input":"2025-02-08T04:20:33.332136Z","iopub.status.idle":"2025-02-08T04:20:33.336349Z","shell.execute_reply.started":"2025-02-08T04:20:33.332114Z","shell.execute_reply":"2025-02-08T04:20:33.335454Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"35+63","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:20:19.198065Z","iopub.status.idle":"2025-02-08T04:20:19.198375Z","shell.execute_reply":"2025-02-08T04:20:19.198248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import openai\nimport pandas as pd\nfrom langchain.prompts.chat import ChatPromptTemplate\nfrom langchain.chat_models import AzureChatOpenAI\nfrom langchain.schema import SystemMessage, HumanMessage\nfrom tqdm import tqdm  # Import tqdm for progress tracking\n\nChat_Model = {\n    \"openai_api_type\": \"azure\",\n    \"deployment_name\": 'ic11-hack-43-gpt-4o-mini',\n    \"model_name\": \"gpt-4o-mini\",\n    \"openai_api_base\": \"https://hac-openai-instance-03.openai.azure.com/\",\n    \"openai_api_version\": \"2024-05-01-preview\",\n    \"openai_api_key\": \"8mKCtXvWx2EoLkrx0At91ZMLEWlLXlq9wxyQ33eeXFzXJ9VFxWmKJQQJ99BBACYeBjFXJ3w3AAABACOGrn5G\",\n    # \"temperature\": 0 # 0-1 as you increse it, creativity increses\n}\n\nchat_model = AzureChatOpenAI(openai_api_type=Chat_Model['openai_api_type'],\n                                        deployment_name=Chat_Model['deployment_name'],\n                                        model_name=Chat_Model['model_name'],\n                                        azure_endpoint=Chat_Model['openai_api_base'],\n                                        openai_api_version=Chat_Model['openai_api_version'],\n                                        openai_api_key=Chat_Model['openai_api_key'],\n                                        temperature=0)\n\ndef generate_resolution_with_llm(message):\n    \"\"\"\n    Generates a resolution for a given log message using a language model.\n\n    Args:\n        message (str): The log message.\n\n    Returns:\n        str: The generated resolution from the LLM.\n    \"\"\"\n\n    system_message = SystemMessage(\n        content= \"You are an expert network engineer providing resolutions for network log messages using maximum 200 words.\"#\"You are an expert network engineer providing resolutions for network log messages.\"\n    )\n    human_message = HumanMessage(\n        content=f\"Provide a detailed resolution for the following network log message: {message}\"\n    )\n\n    response = chat_model.invoke([system_message, human_message])\n    return response.content\n\ndef generate_human_message(message, resolution):\n    \"\"\"\n    Generates a human-readable message for the monitoring team, summarizing the issue and resolution.\n\n    Args:\n        message (str): The original log message.\n        resolution (str): The generated resolution.\n\n    Returns:\n        str: The generated human-readable message.\n    \"\"\"\n\n    system_message = SystemMessage(\n        content=\"You are generating a concise, human-readable message for a network monitoring team. Summarize the network issue and the suggested resolution in a way that is easy to understand.\"\n    )\n    human_message = HumanMessage(\n        content=f\"The network log message is: {message}. The suggested resolution is: {resolution}.  Generate a short message (one or two sentences) to inform the monitoring team about the issue and the resolution.\"\n    )\n\n    response = chat_model.invoke([system_message, human_message])\n    return response.content\n\n\ndef add_llm_resolution_and_message_to_csv(input_path, output_path):\n    \"\"\"\n    Adds 'Resolution' and 'Monitoring Message' columns to a CSV file,\n    generating resolutions and messages using a language model.\n\n    Args:\n        input_path (str): Path to the input CSV file.\n        output_path (str): Path to save the output CSV file with resolutions and messages.\n    \"\"\"\n\n    try:\n        df = pd.read_csv(input_path)\n\n        # Initialize tqdm for progress tracking\n        tqdm.pandas(desc=\"Generating Resolutions\")\n\n        # Generate and add resolutions using the LLM with progress tracking\n        df['Resolution'] = df['Message'].progress_apply(generate_resolution_with_llm)\n\n        tqdm.pandas(desc=\"Generating Monitoring Messages\")\n\n        # Generate and add human-readable messages using the LLM, based on the original message and the generated resolution\n        df['Monitoring Message'] = df.progress_apply(lambda row: generate_human_message(row['Message'], row['Resolution']), axis=1)\n\n\n        # Save the DataFrame with resolutions and messages to a new CSV file\n        df.to_csv(output_path, index=False)\n\n        print(f\"Resolutions and monitoring messages generated and saved to {output_path}\")\n\n    except FileNotFoundError:\n        print(f\"Error: The file {input_path} was not found.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\n# Define input and output file paths\ninput_path = \"/kaggle/working/critical_network_data_selected.csv\" #The critical network data file after applying the filter\noutput_path = \"critical_network_data_with_resolution_and_message.csv\"\n\n# Run the function to add resolutions and messages to the CSV file\nadd_llm_resolution_and_message_to_csv(input_path, output_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:20:40.443274Z","iopub.execute_input":"2025-02-08T04:20:40.443629Z","iopub.status.idle":"2025-02-08T04:28:13.979409Z","shell.execute_reply.started":"2025-02-08T04:20:40.443600Z","shell.execute_reply":"2025-02-08T04:28:13.978511Z"}},"outputs":[{"name":"stderr","text":"Generating Resolutions: 100%|██████████| 100/100 [05:22<00:00,  3.22s/it]\nGenerating Monitoring Messages: 100%|██████████| 100/100 [02:11<00:00,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"Resolutions and monitoring messages generated and saved to critical_network_data_with_resolution_and_message.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"df3 = pd.read_csv(\"/kaggle/working/critical_network_data_with_resolution_and_message.csv\")\ndf3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:28:13.980505Z","iopub.execute_input":"2025-02-08T04:28:13.980736Z","iopub.status.idle":"2025-02-08T04:28:13.997219Z","shell.execute_reply.started":"2025-02-08T04:28:13.980716Z","shell.execute_reply":"2025-02-08T04:28:13.996283Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"              Timestamp    Log_Level    IP_Address  \\\n0   2025-01-17 17:48:59    User.Info  10.163.160.2   \n1   2025-01-17 17:48:59  Local4.Info  10.163.160.2   \n2   2025-01-17 18:06:47  Local4.Info  10.163.160.2   \n3   2025-01-17 18:13:59    User.Info  10.163.160.2   \n4   2025-01-17 18:13:59  Local4.Info  10.163.160.2   \n..                  ...          ...           ...   \n95  2025-01-17 19:13:56  Local4.Info  10.163.160.2   \n96  2025-01-17 19:15:32    User.Info  10.163.160.2   \n97  2025-01-17 19:15:32  Local4.Info  10.163.160.2   \n98  2025-01-17 19:19:41  Local4.Info  10.163.160.2   \n99  2025-01-17 19:21:42    User.Info  10.163.160.2   \n\n                                              Message  \\\n0   dc-pfe[17765]: tvp_drv_syspld_read: i2c access...   \n1   fpc1 tvp_drv_syspld_read: i2c access retry cou...   \n2   fpc4 tvp_drv_syspld_read: i2c access retry cou...   \n3   dc-pfe[17765]: tvp_drv_syspld_read: i2c access...   \n4   fpc1 tvp_drv_syspld_read: i2c access retry cou...   \n..                                                ...   \n95  fpc2 tvp_drv_syspld_read: i2c access retry cou...   \n96  dc-pfe[17765]: tvp_drv_syspld_read: i2c access...   \n97  fpc1 tvp_drv_syspld_read: i2c access retry cou...   \n98  fpc4 tvp_drv_syspld_read: i2c access retry cou...   \n99  dc-pfe[17765]: tvp_drv_syspld_read: i2c access...   \n\n                                           Resolution  \\\n0   The log message \"dc-pfe[17765]: tvp_drv_syspld...   \n1   The log message \"fpc1 tvp_drv_syspld_read: i2c...   \n2   The log message \"fpc4 tvp_drv_syspld_read: i2c...   \n3   The log message \"dc-pfe[17765]: tvp_drv_syspld...   \n4   The log message \"fpc1 tvp_drv_syspld_read: i2c...   \n..                                                ...   \n95  The log message \"fpc2 tvp_drv_syspld_read: i2c...   \n96  The log message \"dc-pfe[17765]: tvp_drv_syspld...   \n97  The log message \"fpc1 tvp_drv_syspld_read: i2c...   \n98  The log message \"fpc4 tvp_drv_syspld_read: i2c...   \n99  The log message \"dc-pfe[17765]: tvp_drv_syspld...   \n\n                                   Monitoring Message  \n0   We are experiencing I2C communication issues, ...  \n1   We are experiencing I2C communication issues w...  \n2   We are experiencing repeated failures in acces...  \n3   We've detected an I2C communication issue with...  \n4   We've detected an I2C communication issue on F...  \n..                                                ...  \n95  We've detected an I2C communication issue indi...  \n96  We've detected an I2C access issue with the SP...  \n97  We are experiencing an I2C communication issue...  \n98  We've detected an I2C communication issue indi...  \n99  We are experiencing repeated failures in readi...  \n\n[100 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>Log_Level</th>\n      <th>IP_Address</th>\n      <th>Message</th>\n      <th>Resolution</th>\n      <th>Monitoring Message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2025-01-17 17:48:59</td>\n      <td>User.Info</td>\n      <td>10.163.160.2</td>\n      <td>dc-pfe[17765]: tvp_drv_syspld_read: i2c access...</td>\n      <td>The log message \"dc-pfe[17765]: tvp_drv_syspld...</td>\n      <td>We are experiencing I2C communication issues, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2025-01-17 17:48:59</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc1 tvp_drv_syspld_read: i2c access retry cou...</td>\n      <td>The log message \"fpc1 tvp_drv_syspld_read: i2c...</td>\n      <td>We are experiencing I2C communication issues w...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2025-01-17 18:06:47</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc4 tvp_drv_syspld_read: i2c access retry cou...</td>\n      <td>The log message \"fpc4 tvp_drv_syspld_read: i2c...</td>\n      <td>We are experiencing repeated failures in acces...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2025-01-17 18:13:59</td>\n      <td>User.Info</td>\n      <td>10.163.160.2</td>\n      <td>dc-pfe[17765]: tvp_drv_syspld_read: i2c access...</td>\n      <td>The log message \"dc-pfe[17765]: tvp_drv_syspld...</td>\n      <td>We've detected an I2C communication issue with...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2025-01-17 18:13:59</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc1 tvp_drv_syspld_read: i2c access retry cou...</td>\n      <td>The log message \"fpc1 tvp_drv_syspld_read: i2c...</td>\n      <td>We've detected an I2C communication issue on F...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>2025-01-17 19:13:56</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc2 tvp_drv_syspld_read: i2c access retry cou...</td>\n      <td>The log message \"fpc2 tvp_drv_syspld_read: i2c...</td>\n      <td>We've detected an I2C communication issue indi...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>2025-01-17 19:15:32</td>\n      <td>User.Info</td>\n      <td>10.163.160.2</td>\n      <td>dc-pfe[17765]: tvp_drv_syspld_read: i2c access...</td>\n      <td>The log message \"dc-pfe[17765]: tvp_drv_syspld...</td>\n      <td>We've detected an I2C access issue with the SP...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>2025-01-17 19:15:32</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc1 tvp_drv_syspld_read: i2c access retry cou...</td>\n      <td>The log message \"fpc1 tvp_drv_syspld_read: i2c...</td>\n      <td>We are experiencing an I2C communication issue...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>2025-01-17 19:19:41</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc4 tvp_drv_syspld_read: i2c access retry cou...</td>\n      <td>The log message \"fpc4 tvp_drv_syspld_read: i2c...</td>\n      <td>We've detected an I2C communication issue indi...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>2025-01-17 19:21:42</td>\n      <td>User.Info</td>\n      <td>10.163.160.2</td>\n      <td>dc-pfe[17765]: tvp_drv_syspld_read: i2c access...</td>\n      <td>The log message \"dc-pfe[17765]: tvp_drv_syspld...</td>\n      <td>We are experiencing repeated failures in readi...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\nimport time\nfrom threading import Thread\n\n# Placeholder functions for sending messages (replace with actual implementation)\ndef send_resolution_to_monitoring_team(resolution, log_message):\n    \"\"\"Simulates sending the resolution to the monitoring team.\"\"\"\n    print(f\"Monitoring Team: Issue detected. Resolution: {resolution}.  Related Log: {log_message}\")\n    # Replace this with your actual implementation (e.g., sending an email,\n    # posting to a Slack channel, calling an API, etc.)\n    time.sleep(1)  # Simulate network delay\n\ndef send_message_to_user(message, log_message):\n    \"\"\"Simulates sending the message to the user.\"\"\"\n    print(f\"User: Alert for your network. Message: {message}. Related Log: {log_message}\")\n    # Replace this with your actual implementation (e.g., sending an SMS,\n    # sending a push notification, etc.)\n    time.sleep(1)  # Simulate network delay\n\n\ndef log_message(message):\n    \"\"\"Simulates logging a message.\"\"\"\n    print(f\"Logging: {message}\")\n    # Replace this with your actual implementation (e.g., writing to a log file\n    # posting to a monitoring system)\n    time.sleep(1)  # Simulate logging delay\n\ndef agent_resolution_extraction(data):\n    \"\"\"\n    Agent that extracts resolution data from the CSV and sends it to the monitoring team.\n    \"\"\"\n    try:\n        for index, row in data.iterrows():\n            resolution = row['Resolution']\n            log_message = row['Message'] # Include the original log message\n            send_resolution_to_monitoring_team(resolution, log_message)\n            log_message(f\"Resolution sent to monitoring team for log: {log_message}\")\n    except Exception as e:\n        print(f\"Error in resolution agent: {e}\")\n\ndef agent_message_extraction(data):\n    \"\"\"\n    Agent that extracts message data from the CSV and sends it to the user.\n    \"\"\"\n    try:\n        for index, row in data.iterrows():\n            message = row['Monitoring Message']\n            log_message = row['Message'] # Include the original log message\n            send_message_to_user(message, log_message)\n            log_message(f\"Message sent to user for log: {log_message}\")\n    except Exception as e:\n        print(f\"Error in message agent: {e}\")\n\ndef main():\n    \"\"\"\n    Main function to read the CSV and start the agents.\n    \"\"\"\n    csv_file = \"/kaggle/working/critical_network_data_with_resolution_and_message.csv\"\n\n    try:\n        df = pd.read_csv(csv_file)\n\n        # Create threads for each agent\n        resolution_thread = Thread(target=agent_resolution_extraction, args=(df,))\n        message_thread = Thread(target=agent_message_extraction, args=(df,))\n\n        # Start the threads\n        print(\"Starting resolution agent...\")\n        resolution_thread.start()\n        print(\"Starting message agent...\")\n        message_thread.start()\n\n        # Wait for the threads to complete (optional)\n        resolution_thread.join()\n        print(\"Resolution agent finished.\")\n        message_thread.join()\n        print(\"Message agent finished.\")\n\n        print(\"Both agents have completed their tasks.\")\n\n    except FileNotFoundError:\n        print(f\"Error: The file {csv_file} was not found.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:29:12.722154Z","iopub.execute_input":"2025-02-08T04:29:12.722498Z","iopub.status.idle":"2025-02-08T04:29:13.741269Z","shell.execute_reply.started":"2025-02-08T04:29:12.722473Z","shell.execute_reply":"2025-02-08T04:29:13.740335Z"}},"outputs":[{"name":"stdout","text":"Starting resolution agent...\nMonitoring Team: Issue detected. Resolution: The log message \"dc-pfe[17765]: tvp_drv_syspld_read: i2c access retry count 2\" indicates that the system is experiencing issues with I2C communication, specifically during a read operation from the System PLD (Programmable Logic Device). The retry count of 2 suggests that the system attempted to read from the I2C bus twice before logging this message, indicating potential communication problems.\n\n**Resolution Steps:**\n\n1. **Check Connections**: Ensure that all physical connections to the I2C devices are secure. Loose or damaged cables can cause communication failures.\n\n2. **Inspect I2C Devices**: Verify that the I2C devices connected to the bus are functioning correctly. Power cycle the devices if necessary.\n\n3. **Review I2C Configuration**: Check the I2C bus configuration settings in the system. Ensure that the correct addresses and parameters are set.\n\n4. **Monitor Bus Traffic**: Use an oscilloscope or logic analyzer to monitor I2C bus traffic. Look for any abnormal signals or noise that could indicate issues.\n\n5. **Firmware/Driver Update**: Ensure that the firmware and drivers for the I2C controller are up to date. Outdated software can lead to compatibility issues.\n\n6. **Check for Resource Conflicts**: Ensure that no other processes are interfering with I2C communication.\n\nIf the issue persists after these steps, consider escalating to hardware support for further diagnosis..  Related Log: dc-pfe[17765]: tvp_drv_syspld_read: i2c access retry count 2Starting message agent...\n\nUser: Alert for your network. Message: We are experiencing I2C communication issues, as indicated by the log message showing a retry count of 2. Please check physical connections, inspect I2C devices, review configuration settings, and monitor bus traffic; escalate to hardware support if the problem continues.. Related Log: dc-pfe[17765]: tvp_drv_syspld_read: i2c access retry count 2\nError in resolution agent: 'str' object is not callable\nError in message agent: 'str' object is not callable\nResolution agent finished.\nMessage agent finished.\nBoth agents have completed their tasks.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}