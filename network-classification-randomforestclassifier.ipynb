{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10690831,"sourceType":"datasetVersion","datasetId":6624128},{"sourceId":10690970,"sourceType":"datasetVersion","datasetId":6624228}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"/kaggle/input/network-dataset/network_logs.csv\")\nprint(df) \n\n# # Select first 100000 rows\n# df_selected = df.head(100000)\n \n# # Optionally, save it to a new CSV file\n# out_path = \"/kaggle/working/cleaned_data1.csv\"\n# df_selected.to_csv(out_path, index=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:04:09.345273Z","iopub.execute_input":"2025-02-08T04:04:09.345982Z","iopub.status.idle":"2025-02-08T04:04:09.647636Z","shell.execute_reply.started":"2025-02-08T04:04:09.345926Z","shell.execute_reply":"2025-02-08T04:04:09.645889Z"}},"outputs":[{"name":"stdout","text":"                  Timestamp    Log_Level    IP_Address  \\\n0       2025-01-17 17:45:00    Cron.Info  10.163.160.2   \n1       2025-01-17 17:45:00    Cron.Info  10.163.160.2   \n2       2025-01-17 17:45:01    Cron.Info  10.163.160.2   \n3       2025-01-17 17:48:59    User.Info  10.163.160.2   \n4       2025-01-17 17:48:59  Local4.Info  10.163.160.2   \n...                     ...          ...           ...   \n141480  2025-02-03 22:13:02  Local4.Info  10.163.160.2   \n141481  2025-02-03 22:13:31  Local4.Info  10.163.160.2   \n141482  2025-02-03 22:15:00    Cron.Info  10.163.160.2   \n141483  2025-02-03 22:15:00    Cron.Info  10.163.160.2   \n141484  2025-02-03 22:15:00    Cron.Info  10.163.160.2   \n\n                                                  Message  \n0        /usr/sbin/cron[32897]: (root) CMD (newsyslog -X)  \n1       /usr/sbin/cron[32898]: (root) CMD (   /usr/lib...  \n2       /usr/sbin/cron[32896]: (root) MAIL (mailed 39 ...  \n3       dc-pfe[17765]: tvp_drv_syspld_read: i2c access...  \n4       fpc1 tvp_drv_syspld_read: i2c access retry cou...  \n...                                                   ...  \n141480  fpc0 tvp_drv_syspld_read: i2c access retry cou...  \n141481  fpc4 tvp_drv_syspld_read: i2c access retry cou...  \n141482  /usr/sbin/cron[4759]: (root) CMD (   /usr/libe...  \n141483    /usr/sbin/cron[4758]: (root) CMD (newsyslog -X)  \n141484  /usr/sbin/cron[4757]: (root) MAIL (mailed 39 b...  \n\n[141485 rows x 4 columns]\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"787+84","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:04:09.649696Z","iopub.execute_input":"2025-02-08T04:04:09.650228Z","iopub.status.idle":"2025-02-08T04:04:09.658865Z","shell.execute_reply.started":"2025-02-08T04:04:09.650142Z","shell.execute_reply":"2025-02-08T04:04:09.656815Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"871"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"import pandas as pd\nimport re\n\n# Load the CSV file into a Pandas DataFrame\ndf = pd.read_csv(\"/kaggle/input/network-dataset/network_logs.csv\")\n\n# Convert the 'Timestamp' column to datetime objects\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n\n# Extract date and time into separate columns\ndf['Date'] = df['Timestamp'].dt.date\ndf['Time'] = df['Timestamp'].dt.time\n\n# Function to extract port from the 'Message' column using regex\ndef extract_port(message):\n    match = re.search(r'port\\s*(\\d+)', str(message), re.IGNORECASE)\n    if match:\n        return int(match.group(1))\n    return None\n\n# Apply the function to create a 'Port' column\ndf['Port'] = df['Message'].apply(extract_port)\n\n# Define critical keywords\ncritical_keywords = [\n    \"DOWN\",\n    \"ERROR\",\n    \"FAILURE\",\n    \"CRITICAL\",\n    \"WARNING\",\n    \"REJECTED\",\n    \"Authentication failure\",\n    \"i2c access retry count\",\n    \"ifd_mdown\",  # Interface down\n    \"SNMP_TRAP_LINK_DOWN\"  # Link down trap\n]\n\n# Function to determine if a message is critical\ndef is_critical(message):\n    if isinstance(message, str):\n        for keyword in critical_keywords:\n            if keyword in message.upper():\n                return \"Critical\"\n    return \"Non-Critical\"\n\n# Apply the function to create a 'Critical' column\ndf['Critical'] = df['Message'].apply(is_critical)\n\n# Function to extract CMD or MAIL\ndef extract_cmd_mail(message):\n    if isinstance(message, str):\n        if \"CMD\" in message.upper():\n            return \"CMD\"\n        elif \"MAIL\" in message.upper():\n            return \"MAIL\"\n    return None\n\n# Apply the function to create a 'Type' column\ndf['Type'] = df['Message'].apply(extract_cmd_mail)\n\n# Remove the 'Port' column\ndf = df.drop('Port', axis=1)\n\n# Save the modified DataFrame to a new CSV file\ndf.to_csv(\"data_new.csv\", index=False)\n\n# Display the first few rows of the modified DataFrame\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:04:09.661062Z","iopub.execute_input":"2025-02-08T04:04:09.661482Z","iopub.status.idle":"2025-02-08T04:04:12.268018Z","shell.execute_reply.started":"2025-02-08T04:04:09.661451Z","shell.execute_reply":"2025-02-08T04:04:12.266618Z"}},"outputs":[{"name":"stdout","text":"            Timestamp    Log_Level    IP_Address  \\\n0 2025-01-17 17:45:00    Cron.Info  10.163.160.2   \n1 2025-01-17 17:45:00    Cron.Info  10.163.160.2   \n2 2025-01-17 17:45:01    Cron.Info  10.163.160.2   \n3 2025-01-17 17:48:59    User.Info  10.163.160.2   \n4 2025-01-17 17:48:59  Local4.Info  10.163.160.2   \n\n                                             Message        Date      Time  \\\n0   /usr/sbin/cron[32897]: (root) CMD (newsyslog -X)  2025-01-17  17:45:00   \n1  /usr/sbin/cron[32898]: (root) CMD (   /usr/lib...  2025-01-17  17:45:00   \n2  /usr/sbin/cron[32896]: (root) MAIL (mailed 39 ...  2025-01-17  17:45:01   \n3  dc-pfe[17765]: tvp_drv_syspld_read: i2c access...  2025-01-17  17:48:59   \n4  fpc1 tvp_drv_syspld_read: i2c access retry cou...  2025-01-17  17:48:59   \n\n       Critical  Type  \n0  Non-Critical   CMD  \n1  Non-Critical   CMD  \n2  Non-Critical  MAIL  \n3  Non-Critical  None  \n4  Non-Critical  None  \n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/working/data_new.csv\")\ndf1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:04:12.269775Z","iopub.execute_input":"2025-02-08T04:04:12.270317Z","iopub.status.idle":"2025-02-08T04:04:12.657447Z","shell.execute_reply.started":"2025-02-08T04:04:12.270262Z","shell.execute_reply":"2025-02-08T04:04:12.656043Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"                  Timestamp    Log_Level    IP_Address  \\\n0       2025-01-17 17:45:00    Cron.Info  10.163.160.2   \n1       2025-01-17 17:45:00    Cron.Info  10.163.160.2   \n2       2025-01-17 17:45:01    Cron.Info  10.163.160.2   \n3       2025-01-17 17:48:59    User.Info  10.163.160.2   \n4       2025-01-17 17:48:59  Local4.Info  10.163.160.2   \n...                     ...          ...           ...   \n141480  2025-02-03 22:13:02  Local4.Info  10.163.160.2   \n141481  2025-02-03 22:13:31  Local4.Info  10.163.160.2   \n141482  2025-02-03 22:15:00    Cron.Info  10.163.160.2   \n141483  2025-02-03 22:15:00    Cron.Info  10.163.160.2   \n141484  2025-02-03 22:15:00    Cron.Info  10.163.160.2   \n\n                                                  Message        Date  \\\n0        /usr/sbin/cron[32897]: (root) CMD (newsyslog -X)  2025-01-17   \n1       /usr/sbin/cron[32898]: (root) CMD (   /usr/lib...  2025-01-17   \n2       /usr/sbin/cron[32896]: (root) MAIL (mailed 39 ...  2025-01-17   \n3       dc-pfe[17765]: tvp_drv_syspld_read: i2c access...  2025-01-17   \n4       fpc1 tvp_drv_syspld_read: i2c access retry cou...  2025-01-17   \n...                                                   ...         ...   \n141480  fpc0 tvp_drv_syspld_read: i2c access retry cou...  2025-02-03   \n141481  fpc4 tvp_drv_syspld_read: i2c access retry cou...  2025-02-03   \n141482  /usr/sbin/cron[4759]: (root) CMD (   /usr/libe...  2025-02-03   \n141483    /usr/sbin/cron[4758]: (root) CMD (newsyslog -X)  2025-02-03   \n141484  /usr/sbin/cron[4757]: (root) MAIL (mailed 39 b...  2025-02-03   \n\n            Time      Critical  Type  \n0       17:45:00  Non-Critical   CMD  \n1       17:45:00  Non-Critical   CMD  \n2       17:45:01  Non-Critical  MAIL  \n3       17:48:59  Non-Critical   NaN  \n4       17:48:59  Non-Critical   NaN  \n...          ...           ...   ...  \n141480  22:13:02  Non-Critical   NaN  \n141481  22:13:31  Non-Critical   NaN  \n141482  22:15:00  Non-Critical   CMD  \n141483  22:15:00  Non-Critical   CMD  \n141484  22:15:00  Non-Critical  MAIL  \n\n[141485 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>Log_Level</th>\n      <th>IP_Address</th>\n      <th>Message</th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Critical</th>\n      <th>Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2025-01-17 17:45:00</td>\n      <td>Cron.Info</td>\n      <td>10.163.160.2</td>\n      <td>/usr/sbin/cron[32897]: (root) CMD (newsyslog -X)</td>\n      <td>2025-01-17</td>\n      <td>17:45:00</td>\n      <td>Non-Critical</td>\n      <td>CMD</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2025-01-17 17:45:00</td>\n      <td>Cron.Info</td>\n      <td>10.163.160.2</td>\n      <td>/usr/sbin/cron[32898]: (root) CMD (   /usr/lib...</td>\n      <td>2025-01-17</td>\n      <td>17:45:00</td>\n      <td>Non-Critical</td>\n      <td>CMD</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2025-01-17 17:45:01</td>\n      <td>Cron.Info</td>\n      <td>10.163.160.2</td>\n      <td>/usr/sbin/cron[32896]: (root) MAIL (mailed 39 ...</td>\n      <td>2025-01-17</td>\n      <td>17:45:01</td>\n      <td>Non-Critical</td>\n      <td>MAIL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2025-01-17 17:48:59</td>\n      <td>User.Info</td>\n      <td>10.163.160.2</td>\n      <td>dc-pfe[17765]: tvp_drv_syspld_read: i2c access...</td>\n      <td>2025-01-17</td>\n      <td>17:48:59</td>\n      <td>Non-Critical</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2025-01-17 17:48:59</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc1 tvp_drv_syspld_read: i2c access retry cou...</td>\n      <td>2025-01-17</td>\n      <td>17:48:59</td>\n      <td>Non-Critical</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>141480</th>\n      <td>2025-02-03 22:13:02</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc0 tvp_drv_syspld_read: i2c access retry cou...</td>\n      <td>2025-02-03</td>\n      <td>22:13:02</td>\n      <td>Non-Critical</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>141481</th>\n      <td>2025-02-03 22:13:31</td>\n      <td>Local4.Info</td>\n      <td>10.163.160.2</td>\n      <td>fpc4 tvp_drv_syspld_read: i2c access retry cou...</td>\n      <td>2025-02-03</td>\n      <td>22:13:31</td>\n      <td>Non-Critical</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>141482</th>\n      <td>2025-02-03 22:15:00</td>\n      <td>Cron.Info</td>\n      <td>10.163.160.2</td>\n      <td>/usr/sbin/cron[4759]: (root) CMD (   /usr/libe...</td>\n      <td>2025-02-03</td>\n      <td>22:15:00</td>\n      <td>Non-Critical</td>\n      <td>CMD</td>\n    </tr>\n    <tr>\n      <th>141483</th>\n      <td>2025-02-03 22:15:00</td>\n      <td>Cron.Info</td>\n      <td>10.163.160.2</td>\n      <td>/usr/sbin/cron[4758]: (root) CMD (newsyslog -X)</td>\n      <td>2025-02-03</td>\n      <td>22:15:00</td>\n      <td>Non-Critical</td>\n      <td>CMD</td>\n    </tr>\n    <tr>\n      <th>141484</th>\n      <td>2025-02-03 22:15:00</td>\n      <td>Cron.Info</td>\n      <td>10.163.160.2</td>\n      <td>/usr/sbin/cron[4757]: (root) MAIL (mailed 39 b...</td>\n      <td>2025-02-03</td>\n      <td>22:15:00</td>\n      <td>Non-Critical</td>\n      <td>MAIL</td>\n    </tr>\n  </tbody>\n</table>\n<p>141485 rows × 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"df1.Log_Level.unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:04:12.658868Z","iopub.execute_input":"2025-02-08T04:04:12.659412Z","iopub.status.idle":"2025-02-08T04:04:12.677427Z","shell.execute_reply.started":"2025-02-08T04:04:12.659366Z","shell.execute_reply":"2025-02-08T04:04:12.676233Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"array(['Cron.Info', 'User.Info', 'Local4.Info', 'Daemon.Info',\n       'Daemon.Warning', 'Daemon.Notice', 'Auth.Info', 'Local7.Info'],\n      dtype=object)"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom imblearn.over_sampling import SMOTE\nimport numpy as np\n\n# Load the CSV file\ndf = pd.read_csv(\"data_new.csv\")\n\n# Convert 'Timestamp' column to datetime objects\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n\n# Extract time-based features\ndf['Hour'] = df['Timestamp'].dt.hour\ndf['DayOfWeek'] = df['Timestamp'].dt.dayofweek  # 0 = Monday, 6 = Sunday\ndf['Month'] = df['Timestamp'].dt.month\n\n# Define categorical and numerical features\ncategorical_features = ['Type']\nnumerical_features = ['Hour', 'DayOfWeek', 'Month']\n\n# Define the target variable\ntarget = 'Critical'\n\n# Separate features and target variable\nX = df[numerical_features + categorical_features].copy()\ny = df[target].copy()\n\n# Convert categorical columns to string\nfor col in categorical_features:\n    X[col] = X[col].astype(str)\n\n# Preprocessing\npreprocessor = ColumnTransformer([\n    ('num', 'passthrough', numerical_features),\n    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n])\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Transform data\nX_train = preprocessor.fit_transform(X_train)\nX_test = preprocessor.transform(X_test)\n\n# Handle Class Imbalance with SMOTE\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# Define hyperparameter grid (smaller set for speed)\nparam_grid = {\n    'n_estimators': [100, 200],  # Reduced options\n    'max_depth': [None, 10],  # Fewer depths\n    'min_samples_split': [2, 5],  # Limited choices\n    'class_weight': ['balanced', None]\n}\n\n# Initialize RandomForestClassifier with warm_start for efficiency\nmodel = RandomForestClassifier(random_state=42, warm_start=True)\n\n# Use RandomizedSearchCV instead of GridSearchCV (much faster)\nrandom_search = RandomizedSearchCV(\n    model, param_grid, cv=2, scoring='accuracy', n_iter=5, n_jobs=-1, verbose=1, random_state=42\n)\n\n# Train model\nrandom_search.fit(X_train_resampled, y_train_resampled)\n\n# Best model\nbest_model = random_search.best_estimator_\n\n# Make predictions\ny_pred = best_model.predict(X_test)\n\n# Evaluate\naccuracy = accuracy_score(y_test, y_pred)\nreport = classification_report(y_test, y_pred)\n\nprint(f\"Best parameters found: {random_search.best_params_}\")\nprint(f\"Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:04:12.678871Z","iopub.execute_input":"2025-02-08T04:04:12.679334Z","iopub.status.idle":"2025-02-08T04:04:57.808628Z","shell.execute_reply.started":"2025-02-08T04:04:12.679292Z","shell.execute_reply":"2025-02-08T04:04:57.806820Z"}},"outputs":[{"name":"stdout","text":"Fitting 2 folds for each of 5 candidates, totalling 10 fits\nBest parameters found: {'n_estimators': 100, 'min_samples_split': 5, 'max_depth': 10, 'class_weight': None}\nAccuracy: 0.4621\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom imblearn.over_sampling import SMOTE\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset\ndf = pd.read_csv(\"data_new.csv\")\n\n# Convert 'Critical' column from object to binary (0 = Non-Critical, 1 = Critical)\ndf['Critical'] = df['Critical'].map({'Non-Critical': 0, 'Critical': 1})\n\n# Drop unnecessary columns\ndf.drop(columns=['Timestamp', 'IP_Address'], inplace=True, errors='ignore')\n\n# Extract time-based features\ndf['Hour'] = pd.to_datetime(df['Date'] + ' ' + df['Time']).dt.hour\ndf['DayOfWeek'] = pd.to_datetime(df['Date']).dt.dayofweek  # 0 = Monday, 6 = Sunday\ndf['Month'] = pd.to_datetime(df['Date']).dt.month\n\n# Define categorical and numerical features\ncategorical_features = ['Type']\nnumerical_features = ['Hour', 'DayOfWeek', 'Month']\n\n# Separate features and target variable\nX = df[numerical_features + categorical_features].copy()\ny = df['Critical'].copy()\n\n# Convert categorical columns to string\nfor col in categorical_features:\n    X[col] = X[col].astype(str)\n\n# Preprocessing pipeline\npreprocessor = ColumnTransformer([\n    ('num', 'passthrough', numerical_features),\n    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n])\n\n# Balance the dataset with 10,000 rows per class\ncritical_df = df[df['Critical'] == 1]\nnon_critical_df = df[df['Critical'] == 0]\n\n# Ensure there is data to sample\nif critical_df.empty or non_critical_df.empty:\n    raise ValueError(\"One of the classes has 0 samples after conversion. Check data preprocessing.\")\n\ncritical_sample = critical_df.sample(n=min(40000, len(critical_df)), random_state=42, replace=len(critical_df) < 40000)\nnon_critical_sample = non_critical_df.sample(n=min(40000, len(non_critical_df)), random_state=42, replace=len(non_critical_df) < 40000)\n\n# Combine and shuffle\ndf_balanced = pd.concat([critical_sample, non_critical_sample]).sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Prepare balanced features and target variable\nX_balanced = df_balanced[numerical_features + categorical_features]\ny_balanced = df_balanced['Critical']\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced)\n\n# Transform data\nX_train = preprocessor.fit_transform(X_train)\nX_test = preprocessor.transform(X_test)\n\n# Handle Class Imbalance with SMOTE\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# Define hyperparameter grid for XGBoost\nparam_grid = {\n    'n_estimators': [100, 200],\n    'max_depth': [6, 10],\n    'learning_rate': [0.01, 0.1],\n    'subsample': [0.8, 1.0]\n}\n\n# Initialize XGBoost classifier\nmodel = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n\n# Use RandomizedSearchCV for tuning\nrandom_search = RandomizedSearchCV(\n    model, param_grid, cv=3, scoring='accuracy', n_iter=5, n_jobs=-1, verbose=1, random_state=42\n)\n\n# Train model\nrandom_search.fit(X_train_resampled, y_train_resampled)\n\n# Best model\nbest_model = random_search.best_estimator_\n\n# Make predictions\ny_pred = best_model.predict(X_test)\n\n# Evaluate performance\naccuracy = accuracy_score(y_test, y_pred)\nreport = classification_report(y_test, y_pred)\n\nprint(f\"Best parameters found: {random_search.best_params_}\")\nprint(f\"Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:04:57.810207Z","iopub.execute_input":"2025-02-08T04:04:57.810695Z","iopub.status.idle":"2025-02-08T04:05:04.094954Z","shell.execute_reply.started":"2025-02-08T04:04:57.810642Z","shell.execute_reply":"2025-02-08T04:05:04.093801Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 5 candidates, totalling 15 fits\nBest parameters found: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.01}\nAccuracy: 0.5694\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nimport numpy as np\n\n# Load the data\ndf = pd.read_csv('data_new.csv')\n\n# Drop unnecessary columns\ndf = df.drop(['Timestamp', 'IP_Address', 'Date', 'Time'], axis=1)\n\n# Handle missing values (fill with 'unknown')\ndf = df.fillna('unknown')\n\n# Encode categorical features\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        df[column] = df[column].astype('category')\n        df[column] = df[column].cat.codes\n\n# Split data into features (X) and target (y)\nX = df.drop('Log_Level', axis=1)\ny = df['Log_Level']\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Scale numerical features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Initialize and train the model\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy:.2f}')\n\n# Print classification report\nprint(classification_report(y_test, y_pred, zero_division=0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T04:05:04.097275Z","iopub.execute_input":"2025-02-08T04:05:04.097616Z","iopub.status.idle":"2025-02-08T04:05:09.830832Z","shell.execute_reply.started":"2025-02-08T04:05:04.097589Z","shell.execute_reply":"2025-02-08T04:05:09.829272Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 1.00\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       1.00      1.00      1.00      2386\n           2       1.00      1.00      1.00     16362\n           3       1.00      1.00      1.00       922\n           4       1.00      1.00      1.00       897\n           5       1.00      1.00      1.00      6260\n           6       1.00      1.00      1.00         1\n           7       1.00      1.00      1.00      1468\n\n    accuracy                           1.00     28297\n   macro avg       0.87      0.88      0.87     28297\nweighted avg       1.00      1.00      1.00     28297\n\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}